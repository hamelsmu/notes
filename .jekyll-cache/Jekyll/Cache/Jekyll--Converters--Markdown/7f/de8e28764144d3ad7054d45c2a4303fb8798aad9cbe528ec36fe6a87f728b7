I"kù<h1 id="fastai-notes">Fastai Notes</h1>

<details open="">
  <summary class="text-delta">
    Table of contents
  </summary>
<ol id="markdown-toc">
  <li><a href="#fastai-notes" id="markdown-toc-fastai-notes">Fastai Notes</a>    <ol>
      <li><a href="#dataloaders" id="markdown-toc-dataloaders">DataLoaders</a></li>
      <li><a href="#datablocks" id="markdown-toc-datablocks">DataBlocks</a></li>
      <li><a href="#training" id="markdown-toc-training">Training</a>        <ol>
          <li><a href="#interpetability" id="markdown-toc-interpetability">Interpetability</a></li>
          <li><a href="#cleaning" id="markdown-toc-cleaning">Cleaning</a></li>
          <li><a href="#loading--saving" id="markdown-toc-loading--saving">Loading / Saving</a></li>
          <li><a href="#predicting" id="markdown-toc-predicting">Predicting</a></li>
        </ol>
      </li>
      <li><a href="#computer-vision" id="markdown-toc-computer-vision">Computer Vision</a>        <ol>
          <li><a href="#pixel-similarity-baseline" id="markdown-toc-pixel-similarity-baseline">Pixel Similarity Baseline</a></li>
          <li><a href="#numpy" id="markdown-toc-numpy">numpy</a></li>
        </ol>
      </li>
      <li><a href="#sgd-from-scratch" id="markdown-toc-sgd-from-scratch">SGD from scratch</a>        <ol>
          <li><a href="#minimal-example" id="markdown-toc-minimal-example">Minimal Example</a></li>
          <li><a href="#mnist" id="markdown-toc-mnist">MNIST</a>            <ol>
              <li><a href="#mini-batch-sgd" id="markdown-toc-mini-batch-sgd">Mini Batch SGD</a>                <ol>
                  <li><a href="#create-a-dataloader" id="markdown-toc-create-a-dataloader">Create a dataloader</a></li>
                </ol>
              </li>
              <li><a href="#the-training-loop" id="markdown-toc-the-training-loop">The Training Loop</a></li>
            </ol>
          </li>
        </ol>
      </li>
    </ol>
  </li>
</ol>

</details>

<h2 id="dataloaders">DataLoaders</h2>

<p><code class="highlighter-rouge">DataLoaders</code> is a thin class around <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#preparing-your-data-for-training-with-dataloaders">DataLoader</a>, and makes them available as <code class="highlighter-rouge">train</code> and <code class="highlighter-rouge">valid</code>.</p>

<p>Same thing applies to <code class="highlighter-rouge">Datasets</code> and <code class="highlighter-rouge">Dataset</code>.</p>

<p>In pytorch, <code class="highlighter-rouge">Dataset</code> is fed into a <code class="highlighter-rouge">DataLoader</code>.</p>

<h2 id="datablocks">DataBlocks</h2>

<blockquote>
  <p>Use this to create <code class="highlighter-rouge">DataLoaders</code></p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="n">bears</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">ImageBlock</span><span class="p">,</span> <span class="n">CategoryBlock</span><span class="p">),</span> 
    <span class="n">get_items</span><span class="o">=</span><span class="n">get_image_files</span><span class="p">,</span> 
    <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">(</span><span class="n">valid_pct</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="n">get_y</span><span class="o">=</span><span class="n">parent_label</span><span class="p">,</span>
    <span class="n">item_tfms</span><span class="o">=</span><span class="n">Resize</span><span class="p">(</span><span class="mi">128</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><code class="highlighter-rouge">DataBlocks</code> are a template for creating <code class="highlighter-rouge">DataLoaders</code>, and need to be instantiated somehow - for example given a path where to find the data:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">dls</span> <span class="o">=</span> <span class="n">bears</span><span class="p">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>You can modify the settings of a <code class="highlighter-rouge">DataBlock</code> with <code class="highlighter-rouge">new</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">bears</span> <span class="o">=</span> <span class="n">bears</span><span class="p">.</span><span class="n">new</span><span class="p">(</span><span class="n">item_tfms</span><span class="o">=</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">min_scale</span><span class="o">=</span><span class="mf">0.3</span><span class="p">))</span> <span class="c1">#book has more examples
</span><span class="n">dls</span> <span class="o">=</span> <span class="n">bears</span><span class="p">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>You can sanity check / see transformed data with <code class="highlighter-rouge">show_batch</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">dls</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">unique</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="p">...</span> <span class="n">images</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>You also use <code class="highlighter-rouge">DataBlocks</code> for data augmentation, with <code class="highlighter-rouge">batch_tfms</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="n">bears</span> <span class="o">=</span> <span class="n">bears</span><span class="p">.</span><span class="n">new</span><span class="p">(</span>
    <span class="n">item_tfms</span><span class="o">=</span><span class="n">Resize</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span>        
    <span class="n">batch_tfms</span><span class="o">=</span><span class="n">aug_transforms</span><span class="p">(</span><span class="n">mult</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">bears</span><span class="p">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">dls</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">unique</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="training">Training</h2>

<p>Most things use <code class="highlighter-rouge">learn.fine_tune()</code>, when you cannot fine-tune like tabular data, you often use <code class="highlighter-rouge">learn.fit_one_cycle</code></p>

<p>You can also do <code class="highlighter-rouge">learn.show_results(...)</code></p>

<h3 id="interpetability">Interpetability</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">interp</span> <span class="o">=</span> <span class="n">ClassificationInterpretation</span><span class="p">.</span><span class="n">from_learner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
<span class="n">interp</span><span class="p">.</span><span class="n">plot_confusion_matrix</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Also see top losses:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">interp</span><span class="p">.</span><span class="n">plot_top_losses</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="cleaning">Cleaning</h3>

<p>You can get a <code class="highlighter-rouge">ImageClassifierCleaner</code> which allows you to choose (1) a category and (2) data partition (train/val) and shows you the highest loss items so you can decide whether to Keep, Delete, Change etc.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">cleaner</span> <span class="o">=</span> <span class="n">ImageClassifierCleaner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
<span class="n">cleaner</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The thing doesn‚Äôt actually delete/change anything but gives you the idxs that allow you to do things with them</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">cleaner</span><span class="p">.</span><span class="n">delete</span><span class="p">():</span> <span class="n">cleaner</span><span class="p">.</span><span class="n">fns</span><span class="p">[</span><span class="n">idx</span><span class="p">].</span><span class="n">unlink</span><span class="p">()</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span><span class="n">cat</span> <span class="ow">in</span> <span class="n">cleaner</span><span class="p">.</span><span class="n">change</span><span class="p">():</span> <span class="n">shutil</span><span class="p">.</span><span class="n">move</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">cleaner</span><span class="p">.</span><span class="n">fns</span><span class="p">[</span><span class="n">idx</span><span class="p">]),</span> <span class="n">path</span><span class="o">/</span><span class="n">cat</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="loading--saving">Loading / Saving</h3>

<p>Saving a model can be done with <code class="highlighter-rouge">learn.export</code>, when you do this, fastai will save a file called ‚Äúexport.pkl‚Äù</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">learn</span><span class="p">.</span><span class="n">export</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><code class="highlighter-rouge">load_learner</code> can be used to load a model</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">learn_inf</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s">'export.pkl'</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="predicting">Predicting</h3>

<p>When you call predict,  you will get three things: (1) class, (2) the index of the predicted category (3) Probabilities of each category</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">learn_inf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="s">'images/grizzly.jpg'</span><span class="p">)</span>
<span class="p">(</span><span class="s">'grizzly'</span><span class="p">,</span> <span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">9.0767e-06</span><span class="p">,</span> <span class="mf">9.9999e-01</span><span class="p">,</span> <span class="mf">1.5748e-07</span><span class="p">]))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>You can see all the classes with <code class="highlighter-rouge">dls.vocab</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">learn_inf</span><span class="p">.</span><span class="n">dls</span><span class="p">.</span><span class="n">vocab</span>
<span class="p">(</span><span class="c1">#3) ['black','grizzly','teddy']
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>Zach: <code class="highlighter-rouge">learn.dls.vocab</code> or <code class="highlighter-rouge">learn.dls.categorize.vocab</code> is another way to get the class names.</p>

<h2 id="computer-vision">Computer Vision</h2>

<p>You can open an image with <code class="highlighter-rouge">Pilow (PIL)</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre><span class="n">im3</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">im3_path</span><span class="p">)</span>
<span class="n">im3</span>

<span class="c1">#convert to numpy
</span><span class="n">array</span><span class="p">(</span><span class="n">im3</span><span class="p">)</span>
<span class="c1"># convert to pytorch tensor
</span><span class="n">tensor</span><span class="p">(</span><span class="n">im3</span><span class="p">)</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="pixel-similarity-baseline">Pixel Similarity Baseline</h3>
<ol>
  <li>Compute avg pixel value for 3‚Äôs and 7‚Äôs</li>
  <li>At inference time, see which one its similar too, using <code class="highlighter-rouge">RMSE (L2 Norm)</code> and <code class="highlighter-rouge">MAE (L1 Norm)</code></li>
</ol>

<p><em>Kind of like KNN</em></p>

<p>Taking an inference tensor, <code class="highlighter-rouge">a_3</code> and calculate distance to mean 3 and 7:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="c1"># MAE &amp; RMSE for 3  vs avg3
</span><span class="n">dist_3_abs</span> <span class="o">=</span> <span class="p">(</span><span class="n">a_3</span> <span class="o">-</span> <span class="n">mean3</span><span class="p">).</span><span class="nb">abs</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>
<span class="n">dist_3_sqr</span> <span class="o">=</span> <span class="p">((</span><span class="n">a_3</span> <span class="o">-</span> <span class="n">mean3</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="n">sqrt</span><span class="p">()</span>

<span class="c1"># MAE &amp; RMSE for 3  vs avg7
</span><span class="n">dist_7_abs</span> <span class="o">=</span> <span class="p">(</span><span class="n">a_3</span> <span class="o">-</span> <span class="n">mean7</span><span class="p">).</span><span class="nb">abs</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>
<span class="n">dist_7_sqr</span> <span class="o">=</span> <span class="p">((</span><span class="n">a_3</span> <span class="o">-</span> <span class="n">mean7</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="n">sqrt</span><span class="p">()</span>

<span class="c1"># Use Pytorch Losses to do the same thing for 3 vs avg 7
</span><span class="n">F</span><span class="p">.</span><span class="n">l1_loss</span><span class="p">(</span><span class="n">a_3</span><span class="p">.</span><span class="nb">float</span><span class="p">(),</span><span class="n">mean7</span><span class="p">),</span> <span class="n">F</span><span class="p">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">a_3</span><span class="p">,</span><span class="n">mean7</span><span class="p">).</span><span class="n">sqrt</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="numpy">numpy</h3>

<p>Take the mean over an axis:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">mnist_distance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span> 
    <span class="c1">#(-2,1) means take the average of the last 2 axis
</span>    <span class="k">return</span> <span class="p">(</span><span class="n">a</span><span class="o">-</span><span class="n">b</span><span class="p">).</span><span class="nb">abs</span><span class="p">().</span><span class="n">mean</span><span class="p">((</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="sgd-from-scratch">SGD from scratch</h2>

<h3 id="minimal-example">Minimal Example</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre></td><td class="rouge-code"><pre><span class="c1"># the loss function
</span><span class="k">def</span> <span class="nf">mse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">):</span> 
    <span class="k">return</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">).</span><span class="n">square</span><span class="p">().</span><span class="n">mean</span><span class="p">().</span><span class="n">sqrt</span><span class="p">()</span>

<span class="c1"># the function that produces the data
</span><span class="k">def</span> <span class="nf">quadratic</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="p">[.</span><span class="mi">75</span><span class="p">,</span> <span class="o">-</span><span class="mf">25.5</span><span class="p">,</span> <span class="mi">15</span><span class="p">]):</span>
    <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">c</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span><span class="n">c</span> <span class="o">+</span> <span class="n">noise</span>

<span class="c1"># generate training data
</span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">quadratic</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># define the training loop
</span><span class="k">def</span> <span class="nf">apply_step</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">pr</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">1.05e-4</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">quadratic</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">params</span><span class="p">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">params</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">data</span> <span class="o">*</span> <span class="n">lr</span>
    <span class="k">if</span> <span class="n">pr</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    <span class="n">params</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span>

<span class="c1"># initialize random params
</span><span class="n">params</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">params</span><span class="p">.</span><span class="n">requires_grad_</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">params</span><span class="p">.</span><span class="n">requires_grad</span>

<span class="c1"># train the model
</span><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">apply_step</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="mnist">MNIST</h3>

<p>A <code class="highlighter-rouge">Dataset</code> in pytorch is required to return a tuple of (x,y) when indexed.  You can do this in python as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="rouge-code"><pre><span class="c1"># Turn mnist data into vectors 3dim -&gt; 2dim
</span><span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">stacked_threes</span><span class="p">,</span> <span class="n">stacked_sevens</span><span class="p">]).</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
<span class="c1"># Generate label tensor
</span><span class="n">train_y</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">threes</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">sevens</span><span class="p">)).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Create dataset
</span><span class="n">dset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span><span class="n">train_y</span><span class="p">))</span>

<span class="c1"># See shapes from first datum in the dataset
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">dset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span>
<span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">784</span><span class="p">]),</span> <span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>


<span class="c1"># Do the same thing for the validation set
</span><span class="p">....</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="mini-batch-sgd">Mini Batch SGD</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="rouge-code"><pre><span class="c1"># `@` and dot product is the same:
</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">a</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">==</span> <span class="n">a</span><span class="o">@</span><span class="n">b</span>

<span class="c1"># define model
</span><span class="k">def</span> <span class="nf">init_params</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span> 
    <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="p">)</span><span class="o">*</span><span class="n">std</span><span class="p">).</span><span class="n">requires_grad_</span><span class="p">()</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">((</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">linear1</span><span class="p">(</span><span class="n">xb</span><span class="p">):</span> <span class="k">return</span> <span class="n">xb</span><span class="o">@</span><span class="n">weights</span> <span class="o">+</span> <span class="n">bias</span>

<span class="c1">#naive loss (for illustration)
</span><span class="n">corrects</span> <span class="o">=</span> <span class="p">(</span><span class="n">preds</span><span class="o">&gt;</span><span class="mf">0.0</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span> <span class="o">==</span> <span class="n">train_y</span>
<span class="n">corrects</span><span class="p">.</span><span class="nb">float</span><span class="p">().</span><span class="n">mean</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>

<span class="c1"># define loss
</span><span class="k">def</span> <span class="nf">mnist_loss</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">preds</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">()</span> <span class="c1">#squash b/w 0 and 1
</span>    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">targets</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">preds</span><span class="p">,</span> <span class="n">preds</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># average distance loss
</span></pre></td></tr></tbody></table></code></pre></div></div>

<h5 id="create-a-dataloader">Create a dataloader</h5>

<p>You want to load your data in batches, so you will want to create a dataloader.  Recall that in pytorch, a <code class="highlighter-rouge">Dataset</code> is required to return a tuple of (x,y) when indexed, which is quite easy to do:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="c1"># define a data loader using `dset`
</span><span class="n">dset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span><span class="n">train_y</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Pytorch offers a utility to then create a <code class="highlighter-rouge">Dataloader</code> from a dataset, but Jeremy basically rolled his own (w/same api):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="n">valid_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_dset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="the-training-loop">The Training Loop</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mnist_loss</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">xb</span><span class="p">,</span><span class="n">yb</span> <span class="ow">in</span> <span class="n">dl</span><span class="p">:</span>
        <span class="n">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">p</span><span class="p">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">p</span><span class="p">.</span><span class="n">grad</span><span class="o">*</span><span class="n">lr</span>
            <span class="n">p</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span> <span class="c1">#updates in place
</span>
<span class="c1">### Calculate metrics
</span><span class="k">def</span> <span class="nf">batch_accuracy</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">xb</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">preds</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="n">yb</span>
    <span class="k">return</span> <span class="n">correct</span><span class="p">.</span><span class="nb">float</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">validate_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">accs</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">),</span> <span class="n">yb</span><span class="p">)</span> <span class="k">for</span> <span class="n">xb</span><span class="p">,</span><span class="n">yb</span> <span class="ow">in</span> <span class="n">valid_dl</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">accs</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="n">item</span><span class="p">(),</span> <span class="mi">4</span><span class="p">)</span>

<span class="c1"># Train model
</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">bias</span>
<span class="n">train_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">)</span>

<span class="c1"># Train model w/epochs
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">train_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s">' '</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>
:ET