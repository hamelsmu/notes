<h1 id="fastai-fundamentals-from-the-coursebook">fastai fundamentals from the Course/Book</h1>

<p>import TOCInline from ‘@theme/TOCInline’;</p>

<p>&lt;TOCInline toc={toc} /&gt;;</p>

<h2 id="dataloaders">DataLoaders</h2>

<p><code class="language-plaintext highlighter-rouge">DataLoaders</code> is a thin class around <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#preparing-your-data-for-training-with-dataloaders">DataLoader</a>, and makes them available as <code class="language-plaintext highlighter-rouge">train</code> and <code class="language-plaintext highlighter-rouge">valid</code>.</p>

<p>Same thing applies to <code class="language-plaintext highlighter-rouge">Datasets</code> and <code class="language-plaintext highlighter-rouge">Dataset</code>.</p>

<p>In pytorch, <code class="language-plaintext highlighter-rouge">Dataset</code> is fed into a <code class="language-plaintext highlighter-rouge">DataLoader</code>.</p>

<h2 id="datablocks">DataBlocks</h2>

<blockquote>
  <p>Use this to create <code class="language-plaintext highlighter-rouge">DataLoaders</code></p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bears</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">ImageBlock</span><span class="p">,</span> <span class="n">CategoryBlock</span><span class="p">),</span> 
    <span class="n">get_items</span><span class="o">=</span><span class="n">get_image_files</span><span class="p">,</span> 
    <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">(</span><span class="n">valid_pct</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="n">get_y</span><span class="o">=</span><span class="n">parent_label</span><span class="p">,</span>
    <span class="n">item_tfms</span><span class="o">=</span><span class="n">Resize</span><span class="p">(</span><span class="mi">128</span><span class="p">))</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">DataBlocks</code> are a template for creating <code class="language-plaintext highlighter-rouge">DataLoaders</code>, and need to be instantiated somehow - for example given a path where to find the data:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dls</span> <span class="o">=</span> <span class="n">bears</span><span class="p">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</code></pre></div></div>

<p>You can modify the settings of a <code class="language-plaintext highlighter-rouge">DataBlock</code> with <code class="language-plaintext highlighter-rouge">new</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bears</span> <span class="o">=</span> <span class="n">bears</span><span class="p">.</span><span class="n">new</span><span class="p">(</span><span class="n">item_tfms</span><span class="o">=</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">min_scale</span><span class="o">=</span><span class="mf">0.3</span><span class="p">))</span> <span class="c1">#book has more examples
</span><span class="n">dls</span> <span class="o">=</span> <span class="n">bears</span><span class="p">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</code></pre></div></div>

<p>You can sanity check / see transformed data with <code class="language-plaintext highlighter-rouge">show_batch</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">dls</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">unique</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="p">...</span> <span class="n">images</span>
</code></pre></div></div>

<p>You also use <code class="language-plaintext highlighter-rouge">DataBlocks</code> for data augmentation, with <code class="language-plaintext highlighter-rouge">batch_tfms</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bears</span> <span class="o">=</span> <span class="n">bears</span><span class="p">.</span><span class="n">new</span><span class="p">(</span>
    <span class="n">item_tfms</span><span class="o">=</span><span class="n">Resize</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span>        
    <span class="n">batch_tfms</span><span class="o">=</span><span class="n">aug_transforms</span><span class="p">(</span><span class="n">mult</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">bears</span><span class="p">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">dls</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">unique</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="training">Training</h2>

<p>Most things use <code class="language-plaintext highlighter-rouge">learn.fine_tune()</code>, when you cannot fine-tune like tabular data, you often use <code class="language-plaintext highlighter-rouge">learn.fit_one_cycle</code></p>

<p>You can also do <code class="language-plaintext highlighter-rouge">learn.show_results(...)</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="p">.</span><span class="n">PETS</span><span class="p">)</span><span class="o">/</span><span class="s">'images'</span>

<span class="k">def</span> <span class="nf">is_cat</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> 
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">isupper</span><span class="p">()</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">ImageDataLoaders</span><span class="p">.</span><span class="n">from_name_func</span><span class="p">(</span>
        <span class="n">path</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="p">),</span> 
        <span class="n">fnames</span><span class="o">=</span><span class="n">get_image_files</span><span class="p">(</span><span class="n">path</span><span class="p">),</span> 
        <span class="n">valid_pct</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> 
        <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
        <span class="n">label_func</span><span class="o">=</span><span class="n">is_cat</span><span class="p">,</span> 
        <span class="n">item_tfms</span><span class="o">=</span><span class="n">Resize</span><span class="p">(</span><span class="mi">224</span><span class="p">))</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet34</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">)</span>
<span class="n">learn</span><span class="p">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>More info on what this is in later sections.</p>

<h3 id="interpetability">Interpetability</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">interp</span> <span class="o">=</span> <span class="n">ClassificationInterpretation</span><span class="p">.</span><span class="n">from_learner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
<span class="n">interp</span><span class="p">.</span><span class="n">plot_confusion_matrix</span><span class="p">()</span>
</code></pre></div></div>

<p>Also see top losses:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">interp</span><span class="p">.</span><span class="n">plot_top_losses</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="cleaning">Cleaning</h3>

<p>You can get a <code class="language-plaintext highlighter-rouge">ImageClassifierCleaner</code> which allows you to choose (1) a category and (2) data partition (train/val) and shows you the highest loss items so you can decide whether to Keep, Delete, Change etc.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cleaner</span> <span class="o">=</span> <span class="n">ImageClassifierCleaner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
<span class="n">cleaner</span>
</code></pre></div></div>

<p>The thing doesn’t actually delete/change anything but gives you the idxs that allow you to do things with them</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">cleaner</span><span class="p">.</span><span class="n">delete</span><span class="p">():</span> <span class="n">cleaner</span><span class="p">.</span><span class="n">fns</span><span class="p">[</span><span class="n">idx</span><span class="p">].</span><span class="n">unlink</span><span class="p">()</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span><span class="n">cat</span> <span class="ow">in</span> <span class="n">cleaner</span><span class="p">.</span><span class="n">change</span><span class="p">():</span> <span class="n">shutil</span><span class="p">.</span><span class="n">move</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">cleaner</span><span class="p">.</span><span class="n">fns</span><span class="p">[</span><span class="n">idx</span><span class="p">]),</span> <span class="n">path</span><span class="o">/</span><span class="n">cat</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="loading--saving">Loading / Saving</h3>

<p>Saving a model can be done with <code class="language-plaintext highlighter-rouge">learn.export</code>, when you do this, fastai will save a file called “export.pkl”</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="p">.</span><span class="n">export</span><span class="p">()</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">load_learner</code> can be used to load a model</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn_inf</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s">'export.pkl'</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="predicting">Predicting</h3>

<p>When you call predict,  you will get three things: (1) class, (2) the index of the predicted category (3) Probabilities of each category</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">learn_inf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="s">'images/grizzly.jpg'</span><span class="p">)</span>
<span class="p">(</span><span class="s">'grizzly'</span><span class="p">,</span> <span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">9.0767e-06</span><span class="p">,</span> <span class="mf">9.9999e-01</span><span class="p">,</span> <span class="mf">1.5748e-07</span><span class="p">]))</span>
</code></pre></div></div>

<p>You can see all the classes with <code class="language-plaintext highlighter-rouge">dls.vocab</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">learn_inf</span><span class="p">.</span><span class="n">dls</span><span class="p">.</span><span class="n">vocab</span>
<span class="p">(</span><span class="c1">#3) ['black','grizzly','teddy']
</span></code></pre></div></div>

<p>Zach: <code class="language-plaintext highlighter-rouge">learn.dls.vocab</code> or <code class="language-plaintext highlighter-rouge">learn.dls.categorize.vocab</code> is another way to get the class names.</p>

<h2 id="computer-vision">Computer Vision</h2>

<p>You can open an image with <code class="language-plaintext highlighter-rouge">Pilow (PIL)</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">im3</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">im3_path</span><span class="p">)</span>
<span class="n">im3</span>

<span class="c1">#convert to numpy
</span><span class="n">array</span><span class="p">(</span><span class="n">im3</span><span class="p">)</span>
<span class="c1"># convert to pytorch tensor
</span><span class="n">tensor</span><span class="p">(</span><span class="n">im3</span><span class="p">)</span>

</code></pre></div></div>

<h3 id="pixel-similarity-baseline">Pixel Similarity Baseline</h3>
<ol>
  <li>Compute avg pixel value for 3’s and 7’s</li>
  <li>At inference time, see which one its similar too, using <code class="language-plaintext highlighter-rouge">RMSE (L2 Norm)</code> and <code class="language-plaintext highlighter-rouge">MAE (L1 Norm)</code></li>
</ol>

<p><em>Kind of like KNN</em></p>

<p>Taking an inference tensor, <code class="language-plaintext highlighter-rouge">a_3</code> and calculate distance to mean 3 and 7:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># MAE &amp; RMSE for 3  vs avg3
</span><span class="n">dist_3_abs</span> <span class="o">=</span> <span class="p">(</span><span class="n">a_3</span> <span class="o">-</span> <span class="n">mean3</span><span class="p">).</span><span class="nb">abs</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>
<span class="n">dist_3_sqr</span> <span class="o">=</span> <span class="p">((</span><span class="n">a_3</span> <span class="o">-</span> <span class="n">mean3</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="n">sqrt</span><span class="p">()</span>

<span class="c1"># MAE &amp; RMSE for 3  vs avg7
</span><span class="n">dist_7_abs</span> <span class="o">=</span> <span class="p">(</span><span class="n">a_3</span> <span class="o">-</span> <span class="n">mean7</span><span class="p">).</span><span class="nb">abs</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>
<span class="n">dist_7_sqr</span> <span class="o">=</span> <span class="p">((</span><span class="n">a_3</span> <span class="o">-</span> <span class="n">mean7</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="n">sqrt</span><span class="p">()</span>

<span class="c1"># Use Pytorch Losses to do the same thing for 3 vs avg 7
</span><span class="n">F</span><span class="p">.</span><span class="n">l1_loss</span><span class="p">(</span><span class="n">a_3</span><span class="p">.</span><span class="nb">float</span><span class="p">(),</span><span class="n">mean7</span><span class="p">),</span> <span class="n">F</span><span class="p">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">a_3</span><span class="p">,</span><span class="n">mean7</span><span class="p">).</span><span class="n">sqrt</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="numpy">numpy</h3>

<p>Take the mean over an axis:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mnist_distance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span> 
    <span class="c1">#(-2,1) means take the average of the last 2 axis
</span>    <span class="k">return</span> <span class="p">(</span><span class="n">a</span><span class="o">-</span><span class="n">b</span><span class="p">).</span><span class="nb">abs</span><span class="p">().</span><span class="n">mean</span><span class="p">((</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="sgd-from-scratch">SGD from scratch</h2>

<h3 id="minimal-example">Minimal Example</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># the loss function
</span><span class="k">def</span> <span class="nf">mse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">):</span> 
    <span class="k">return</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">).</span><span class="n">square</span><span class="p">().</span><span class="n">mean</span><span class="p">().</span><span class="n">sqrt</span><span class="p">()</span>

<span class="c1"># the function that produces the data
</span><span class="k">def</span> <span class="nf">quadratic</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="p">[.</span><span class="mi">75</span><span class="p">,</span> <span class="o">-</span><span class="mf">25.5</span><span class="p">,</span> <span class="mi">15</span><span class="p">]):</span>
    <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">c</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span><span class="n">c</span> <span class="o">+</span> <span class="n">noise</span>

<span class="c1"># generate training data
</span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">quadratic</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># define the training loop
</span><span class="k">def</span> <span class="nf">apply_step</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">pr</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">1.05e-4</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">quadratic</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">params</span><span class="p">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">params</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">data</span> <span class="o">*</span> <span class="n">lr</span>
    <span class="k">if</span> <span class="n">pr</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="s">f'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    <span class="n">params</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span>

<span class="c1"># initialize random params
</span><span class="n">params</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">params</span><span class="p">.</span><span class="n">requires_grad_</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">params</span><span class="p">.</span><span class="n">requires_grad</span>

<span class="c1"># train the model
</span><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">apply_step</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="mnist">MNIST</h3>

<p>A <code class="language-plaintext highlighter-rouge">Dataset</code> in pytorch is required to return a tuple of (x,y) when indexed.  You can do this in python as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Turn mnist data into vectors 3dim -&gt; 2dim
</span><span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">stacked_threes</span><span class="p">,</span> <span class="n">stacked_sevens</span><span class="p">]).</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
<span class="c1"># Generate label tensor
</span><span class="n">train_y</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">threes</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">sevens</span><span class="p">)).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Create dataset
</span><span class="n">dset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span><span class="n">train_y</span><span class="p">))</span>

<span class="c1"># See shapes from first datum in the dataset
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">dset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span>
<span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">784</span><span class="p">]),</span> <span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>


<span class="c1"># Do the same thing for the validation set
</span><span class="p">....</span>

</code></pre></div></div>

<h4 id="mini-batch-sgd">Mini Batch SGD</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># `@` and dot product is the same:
</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">a</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">==</span> <span class="n">a</span><span class="o">@</span><span class="n">b</span>

<span class="c1"># define model
</span><span class="k">def</span> <span class="nf">init_params</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span> 
    <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="p">)</span><span class="o">*</span><span class="n">std</span><span class="p">).</span><span class="n">requires_grad_</span><span class="p">()</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">((</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">linear1</span><span class="p">(</span><span class="n">xb</span><span class="p">):</span> <span class="k">return</span> <span class="n">xb</span><span class="o">@</span><span class="n">weights</span> <span class="o">+</span> <span class="n">bias</span>

<span class="c1">#naive loss (for illustration)
</span><span class="n">corrects</span> <span class="o">=</span> <span class="p">(</span><span class="n">preds</span><span class="o">&gt;</span><span class="mf">0.0</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span> <span class="o">==</span> <span class="n">train_y</span>
<span class="n">corrects</span><span class="p">.</span><span class="nb">float</span><span class="p">().</span><span class="n">mean</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>

<span class="c1"># define loss
</span><span class="k">def</span> <span class="nf">mnist_loss</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">preds</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">()</span> <span class="c1">#squash b/w 0 and 1
</span>    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">targets</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">preds</span><span class="p">,</span> <span class="n">preds</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># average distance loss
</span></code></pre></div></div>

<h5 id="create-a-dataloader">Create a dataloader</h5>

<p>You want to load your data in batches, so you will want to create a dataloader.  Recall that in pytorch, a <code class="language-plaintext highlighter-rouge">Dataset</code> is required to return a tuple of (x,y) when indexed, which is quite easy to do:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># define a data loader using `dset`
</span><span class="n">dset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span><span class="n">train_y</span><span class="p">))</span>
</code></pre></div></div>

<p>Pytorch offers a utility to then create a <code class="language-plaintext highlighter-rouge">Dataloader</code> from a dataset, but Jeremy basically rolled his own (w/same api):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="n">valid_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_dset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="the-training-loop">The Training Loop</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mnist_loss</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">xb</span><span class="p">,</span><span class="n">yb</span> <span class="ow">in</span> <span class="n">dl</span><span class="p">:</span>
        <span class="n">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">p</span><span class="p">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">p</span><span class="p">.</span><span class="n">grad</span><span class="o">*</span><span class="n">lr</span>
            <span class="n">p</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span> <span class="c1">#updates in place
</span>
<span class="c1">### Calculate metrics
</span><span class="k">def</span> <span class="nf">batch_accuracy</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">xb</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">preds</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="n">yb</span>
    <span class="k">return</span> <span class="n">correct</span><span class="p">.</span><span class="nb">float</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">validate_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">accs</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">),</span> <span class="n">yb</span><span class="p">)</span> <span class="k">for</span> <span class="n">xb</span><span class="p">,</span><span class="n">yb</span> <span class="ow">in</span> <span class="n">valid_dl</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">accs</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="n">item</span><span class="p">(),</span> <span class="mi">4</span><span class="p">)</span>

<span class="c1"># Train model
</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">bias</span>
<span class="n">train_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">)</span>

<span class="c1"># Train model w/epochs
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">train_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s">' '</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="using-pytorch">Using Pytorch</h3>

<p>Blueprint:</p>
<ol>
  <li>Define a dataset and then a dataloader</li>
  <li>Create a model, which will have parameters</li>
  <li>Create an optimizer, that:
    <ul>
      <li>Updates the params: params.data -= parmas.grad.data * lr</li>
      <li>Zeros out the gradients: setting <code class="language-plaintext highlighter-rouge">params.grad = None</code> or zeroing out the gradients with <code class="language-plaintext highlighter-rouge">params.grad.zero_()</code></li>
    </ul>
  </li>
  <li>Generate the predictions</li>
  <li>Calculate the loss</li>
  <li>Calculate the gradients <code class="language-plaintext highlighter-rouge">loss.backward()</code></li>
  <li>Using the optimizer, update the weights <code class="language-plaintext highlighter-rouge">step</code> and zero out the gradients <code class="language-plaintext highlighter-rouge">zero_grad</code></li>
  <li>Put 4-7 in a loop.</li>
</ol>

<p>Create an optimizer and use <code class="language-plaintext highlighter-rouge">nn.Linear</code></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">linear_model</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">w</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="n">linear_model</span><span class="p">.</span><span class="n">parameters</span><span class="p">()</span>

<span class="c1"># Define an optimizer
</span><span class="k">class</span> <span class="nc">BasicOptim</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">params</span><span class="p">,</span><span class="n">lr</span><span class="p">):</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">,</span><span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">params</span><span class="p">),</span><span class="n">lr</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">:</span> <span class="n">p</span><span class="p">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">p</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">data</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span>

    <span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">:</span> <span class="n">p</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">BasicOptim</span><span class="p">(</span><span class="n">linear_model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="p">)</span>
<span class="c1"># alternative, fastai provides SGD
</span><span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">linear_model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="p">)</span>

<span class="c1"># Define Metrics
</span><span class="k">def</span> <span class="nf">batch_accuracy</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">xb</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">preds</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="n">yb</span>
    <span class="k">return</span> <span class="n">correct</span><span class="p">.</span><span class="nb">float</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Helper to calculate metrics on validation set
</span><span class="k">def</span> <span class="nf">validate_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">accs</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">),</span> <span class="n">yb</span><span class="p">)</span> <span class="k">for</span> <span class="n">xb</span><span class="p">,</span><span class="n">yb</span> <span class="ow">in</span> <span class="n">valid_dl</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">accs</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="n">item</span><span class="p">(),</span> <span class="mi">4</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">xb</span><span class="p">,</span><span class="n">yb</span> <span class="ow">in</span> <span class="n">dl</span><span class="p">:</span>
        <span class="n">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="n">opt</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">opt</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">validate_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s">' '</span><span class="p">)</span>


<span class="n">train_model</span><span class="p">(</span><span class="n">linear_model</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="using-fastai">Using fastai</h4>

<p>We can substitute the above with <code class="language-plaintext highlighter-rouge">learner.fit</code> from fastai
We just have to supply the following:</p>

<ol>
  <li>Dataloaders</li>
  <li>Model</li>
  <li>Optimization function</li>
  <li>Loss function</li>
  <li>Metrics</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dls</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="p">(</span><span class="n">dl</span><span class="p">,</span> <span class="n">valid_dl</span><span class="p">)</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">SGD</span><span class="p">,</span> 
                <span class="n">loss_func</span><span class="o">=</span><span class="n">mnist_loss</span><span class="p">,</span>
                <span class="n">metrics</span><span class="o">=</span><span class="n">batch_accuracy</span><span class="p">)</span>

<span class="n">learn</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
</code></pre></div></div>

<p>What if you used the full power of fastai?  It would look like this:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dls</span> <span class="o">=</span> <span class="n">ImageDataLoaders</span><span class="p">.</span><span class="n">from_folder</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="c1"># Lots of things have defaults like optimization func
</span><span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                    <span class="n">loss_func</span><span class="o">=</span><span class="n">F</span><span class="p">.</span><span class="n">cross_entropy</span><span class="p">,</span> 
                     <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="p">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="simple-neural-nets">Simple Neural Nets</h2>

<p>The next step is to introduce a non-linearity</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">simple_net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span>
    <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Construct the learner as before
</span><span class="n">learn</span> <span class="o">=</span> <span class="n">learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">simple_net</span><span class="p">,</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">SGD</span><span class="p">,</span>
               <span class="n">loss_func</span><span class="o">=</span><span class="n">mnist_loss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">batch_accuracy</span><span class="p">)</span>

<span class="n">learner</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="inspecting-training-history">Inspecting Training History</h3>

<p>The training history is saved in <code class="language-plaintext highlighter-rouge">learn.recorder</code>.  You can plot your training progress with:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">learn</span><span class="p">.</span><span class="n">recorder</span><span class="p">.</span><span class="n">values</span><span class="p">).</span><span class="n">itemgot</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>
